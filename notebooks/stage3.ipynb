{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8143fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: c:\\Users\\hp\\OneDrive\\Desktop\\Zine_project1\\rec-temporal-gnn\n",
      "✅ Loaded TGAT checkpoint\n",
      "Val size: 100021\n",
      "P@5=0.0163  R@5=0.0265\n",
      "P@10=0.0245  R@10=0.0584\n",
      "P@20=0.0360  R@20=0.0843\n",
      "\n",
      "User 720 top-5 candidates (item_id, is_positive):\n",
      "    348  1\n",
      "   2258  1\n",
      "   2430  1\n",
      "    593  1\n",
      "    899  1\n"
     ]
    }
   ],
   "source": [
    "# === Stage 3 TGAT: self-contained verification cell ===\n",
    "\n",
    "\n",
    "import os, json, math, random\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# --- Locate repo root (folder that contains 'data/processed') ---\n",
    "def find_repo_root(start=Path.cwd()):\n",
    "    d = start\n",
    "    for _ in range(8):\n",
    "        if (d/\"data/processed\").exists():\n",
    "            return d\n",
    "        if d.parent == d: break\n",
    "        d = d.parent\n",
    "    raise RuntimeError(\"Could not find repo root containing data/processed/\")\n",
    "ROOT = find_repo_root()\n",
    "PROCESSED = ROOT/\"data/processed\"\n",
    "print(\"Repo root:\", ROOT)\n",
    "\n",
    "# --- Inline model (must match training) ---\n",
    "class TimeEncoder(nn.Module):\n",
    "    def __init__(self, dim: int):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.lin = nn.Linear(dim, dim)\n",
    "    def forward(self, t: torch.Tensor):           # t: [E,1] float32\n",
    "        t = t.to(torch.float32)\n",
    "        d = self.dim\n",
    "        freq = torch.arange(d, device=t.device, dtype=t.dtype) / float(d)\n",
    "        scales = 1.0 / (10.0 ** freq)            # [d]\n",
    "        x = t * scales.unsqueeze(0)              # [E,d]\n",
    "        return self.lin(torch.sin(x))            # [E,d]\n",
    "\n",
    "class TemporalTGAT(nn.Module):\n",
    "    def __init__(self, num_users, num_items, hidden=64, time_dim=32):\n",
    "        super().__init__()\n",
    "        from torch_geometric.nn import TransformerConv\n",
    "        self.user_emb = nn.Embedding(num_users, hidden)\n",
    "        self.item_emb = nn.Embedding(num_items, hidden)\n",
    "        nn.init.normal_(self.user_emb.weight, std=0.02)\n",
    "        nn.init.normal_(self.item_emb.weight, std=0.02)\n",
    "        self.time_enc = TimeEncoder(time_dim)\n",
    "        self.conv = TransformerConv(\n",
    "            in_channels=hidden, out_channels=hidden,\n",
    "            heads=2, dropout=0.1, edge_dim=time_dim\n",
    "        )\n",
    "    def forward(self, u_unique, i_unique, edge_index, t_edge):\n",
    "        x_user = self.user_emb(u_unique)     # [U,H]\n",
    "        x_item = self.item_emb(i_unique)     # [I,H]\n",
    "        h = torch.cat([x_user, x_item], dim=0)     # [U+I,H]\n",
    "        eattr = self.time_enc(t_edge)              # [E, T]\n",
    "        out = self.conv(h, edge_index, edge_attr=eattr)\n",
    "        return out\n",
    "\n",
    "# --- Load counts + checkpoint ---\n",
    "counts = json.loads((PROCESSED/\"temporal_counts.json\").read_text())\n",
    "NUM_USERS, NUM_ITEMS = int(counts[\"num_users\"]), int(counts[\"num_items\"])\n",
    "\n",
    "model = TemporalTGAT(NUM_USERS, NUM_ITEMS, hidden=64, time_dim=32).to(DEVICE)\n",
    "state = torch.load(PROCESSED/\"tgat_baseline.pt\", map_location=DEVICE)\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "print(\"✅ Loaded TGAT checkpoint\")\n",
    "\n",
    "# --- Load validation data (already time-sorted by your prep script) ---\n",
    "df = pd.read_csv(PROCESSED/\"temporal_val.csv\")  # columns: user_id, movie_id, label, ts_norm\n",
    "df[\"user_id\"] = df[\"user_id\"].astype(int)\n",
    "df[\"movie_id\"] = df[\"movie_id\"].astype(int)\n",
    "df[\"label\"]    = df[\"label\"].astype(int)\n",
    "print(\"Val size:\", len(df))\n",
    "\n",
    "# --- Per-user evaluation with negative sampling ---\n",
    "def eval_per_user(df, K=10, neg_k=50, sample_users=200):\n",
    "    users = df[\"user_id\"].unique()\n",
    "    if sample_users and len(users) > sample_users:\n",
    "        users = pd.Series(users).sample(sample_users, random_state=42).values\n",
    "\n",
    "    total_prec, total_rec, user_count = 0.0, 0.0, 0\n",
    "\n",
    "    for u in users:\n",
    "        rows = df[df.user_id == u]\n",
    "        pos_items = rows.loc[rows.label == 1, \"movie_id\"].tolist()\n",
    "        if not pos_items:\n",
    "            continue  # no positives for this user in val\n",
    "\n",
    "        # candidate set = all positives + neg_k random negatives\n",
    "        neg_items = set()\n",
    "        while len(neg_items) < min(neg_k*len(pos_items), NUM_ITEMS - len(pos_items)):\n",
    "            r = random.randint(0, NUM_ITEMS-1)\n",
    "            if r not in pos_items:\n",
    "                neg_items.add(r)\n",
    "        neg_items = list(neg_items)\n",
    "\n",
    "        cand_items = pos_items + neg_items\n",
    "        labels = torch.tensor([1]*len(pos_items) + [0]*len(neg_items), dtype=torch.float32, device=DEVICE)\n",
    "        ts = torch.tensor(rows[\"ts_norm\"].iloc[:1].values, dtype=torch.float32, device=DEVICE)  # use user’s first ts as proxy\n",
    "        ts = ts.repeat(len(cand_items), 1)\n",
    "\n",
    "        # ---- Build local bipartite mini-graph ----\n",
    "        u_tensor = torch.tensor([u]*len(cand_items), dtype=torch.long, device=DEVICE)\n",
    "        i_tensor = torch.tensor(cand_items, dtype=torch.long, device=DEVICE)\n",
    "\n",
    "        # relabel to local ids\n",
    "        u_unique, u_inv = torch.unique(u_tensor, return_inverse=True)   # size U=1\n",
    "        i_unique, i_inv = torch.unique(i_tensor, return_inverse=True)\n",
    "        U = u_unique.size(0)\n",
    "\n",
    "        edge_index = torch.stack([u_inv, i_inv + U], dim=0)  # [2,E]\n",
    "\n",
    "        # ---- Forward ----\n",
    "        with torch.no_grad():\n",
    "            out = model(u_unique, i_unique, edge_index, ts)  # [U+I,H]\n",
    "            h_user = out[:U]          # [1,H]\n",
    "            h_item = out[U:]          # [I,H]\n",
    "            scores = (h_user[0].unsqueeze(0) * h_item).sum(dim=-1) / math.sqrt(h_user.size(-1))\n",
    "            probs = torch.sigmoid(scores)\n",
    "\n",
    "        # ---- Top-K metrics per user ----\n",
    "        k = min(K, probs.numel())\n",
    "        topk_idx = torch.topk(probs, k=k).indices\n",
    "        topk_labels = labels[topk_idx]\n",
    "        prec_u = topk_labels.mean().item()\n",
    "        rec_u = topk_labels.sum().item() / max(1, labels.sum().item())\n",
    "\n",
    "        total_prec += prec_u\n",
    "        total_rec  += rec_u\n",
    "        user_count += 1\n",
    "\n",
    "    if user_count == 0:\n",
    "        return 0.0, 0.0\n",
    "    return total_prec / user_count, total_rec / user_count\n",
    "\n",
    "for K in [5, 10, 20]:\n",
    "    p, r = eval_per_user(df, K=K, neg_k=50, sample_users=200)  # evaluate on 200 users for speed\n",
    "    print(f\"P@{K}={p:.4f}  R@{K}={r:.4f}\")\n",
    "\n",
    "# --- Show a few sample recommendations for a random user ---\n",
    "def show_recs(u, topn=5, neg_k=200):\n",
    "    rows = df[df.user_id == u]\n",
    "    if rows.empty:\n",
    "        print(f\"User {u} not in validation slice\"); return\n",
    "    pos_items = rows.loc[rows.label == 1, \"movie_id\"].tolist()\n",
    "    seen = set(pos_items)\n",
    "    neg_items = []\n",
    "    while len(neg_items) < neg_k:\n",
    "        r = random.randint(0, NUM_ITEMS-1)\n",
    "        if r not in seen:\n",
    "            neg_items.append(r)\n",
    "    cand_items = pos_items + neg_items\n",
    "\n",
    "    labels = torch.tensor([1]*len(pos_items) + [0]*len(neg_items), dtype=torch.float32, device=DEVICE)\n",
    "    ts = torch.tensor(rows[\"ts_norm\"].iloc[:1].values, dtype=torch.float32, device=DEVICE).repeat(len(cand_items), 1)\n",
    "\n",
    "    u_tensor = torch.tensor([u]*len(cand_items), dtype=torch.long, device=DEVICE)\n",
    "    i_tensor = torch.tensor(cand_items, dtype=torch.long, device=DEVICE)\n",
    "    u_unique, u_inv = torch.unique(u_tensor, return_inverse=True)\n",
    "    i_unique, i_inv = torch.unique(i_tensor, return_inverse=True)\n",
    "    U = u_unique.size(0)\n",
    "    edge_index = torch.stack([u_inv, i_inv + U], dim=0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(u_unique, i_unique, edge_index, ts)\n",
    "        h_user = out[:U]; h_item = out[U:]\n",
    "        scores = (h_user[0].unsqueeze(0) * h_item).sum(dim=-1) / math.sqrt(h_user.size(-1))\n",
    "        probs = torch.sigmoid(scores).cpu()\n",
    "\n",
    "    # top-n\n",
    "    k = min(topn, probs.numel())\n",
    "    top_idx = torch.topk(probs, k=k).indices.tolist()\n",
    "    rec_items = [cand_items[i] for i in top_idx]\n",
    "    hits = [int(labels.cpu()[i].item()) for i in top_idx]\n",
    "    print(f\"\\nUser {u} top-{k} candidates (item_id, is_positive):\")\n",
    "    for it, h in zip(rec_items, hits):\n",
    "        print(f\"  {it:5d}  {h}\")\n",
    "\n",
    "# display a random user's recs\n",
    "some_user = int(df.sample(1, random_state=7)[\"user_id\"].iloc[0])\n",
    "show_recs(some_user, topn=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
