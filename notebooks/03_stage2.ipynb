{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60c10ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Device: cpu\n",
      "Node types: ['user', 'item', 'genre']\n",
      "Edge types: [('user', 'interacted', 'item'), ('item', 'belongs_to', 'genre'), ('item', 'rev_interacted', 'user'), ('genre', 'rev_belongs_to', 'item')]\n",
      "✅ Weights loaded from: ../data/processed/graphsage_baseline.pt\n",
      "Embeddings shapes: {'item': (2073, 64), 'genre': (18, 64), 'user': (1515, 64)}\n",
      "✅ Quick sanity passed.\n"
     ]
    }
   ],
   "source": [
    "# Minimal Stage-2 sanity: load graph, rebuild identical model, load weights, tiny forward\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import HeteroConv, SAGEConv\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"✅ Device:\", DEVICE)\n",
    "\n",
    "# --- load graphs and add reverse edges exactly like train_stage2.py ---\n",
    "g_train: HeteroData = torch.load(\"../data/processed/graph_train.pt\", weights_only=False)\n",
    "g_train = T.ToUndirected()(g_train)  # adds rev_* edge types\n",
    "g_train = g_train.to(DEVICE)\n",
    "\n",
    "print(\"Node types:\", g_train.node_types)\n",
    "print(\"Edge types:\", g_train.edge_types)\n",
    "\n",
    "# --- rebuild the *same* model used in training ---\n",
    "\n",
    "class FeatEncoder(nn.Module):\n",
    "    def __init__(self, g: HeteroData, hidden: int):\n",
    "        super().__init__()\n",
    "        self.proj = nn.ModuleDict()\n",
    "        for ntype in g.node_types:\n",
    "            in_dim = g[ntype].x.size(-1)\n",
    "            self.proj[ntype] = nn.Linear(in_dim, hidden)\n",
    "\n",
    "    def forward(self, x_dict):\n",
    "        return {nt: F.relu(self.proj[nt](x)) for nt, x in x_dict.items()}\n",
    "\n",
    "class HeteroSAGE(nn.Module):\n",
    "    def __init__(self, g: HeteroData, hidden: int = 64):\n",
    "        super().__init__()\n",
    "        self.encoder = FeatEncoder(g, hidden)\n",
    "        self.layers = nn.ModuleList()\n",
    "        # one SAGE per edge type, for 2 layers, same as train_stage2.py\n",
    "        for _ in range(2):\n",
    "            conv = HeteroConv({et: SAGEConv((-1, -1), hidden) for et in g.edge_types}, aggr=\"sum\")\n",
    "            self.layers.append(conv)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        h = self.encoder(x_dict)\n",
    "        for conv in self.layers:\n",
    "            h = conv(h, edge_index_dict)\n",
    "            h = {k: F.relu(v) for k, v in h.items()}\n",
    "        return h\n",
    "\n",
    "    def decode(self, h_user, h_item, edge_label_index):\n",
    "        src, dst = edge_label_index\n",
    "        return (h_user[src] * h_item[dst]).sum(dim=-1)\n",
    "\n",
    "# instantiate on THIS graph (edge types must match)\n",
    "model = HeteroSAGE(g_train, hidden=64).to(DEVICE)\n",
    "\n",
    "# --- load trained weights (names now match) ---\n",
    "ckpt = \"../data/processed/graphsage_baseline.pt\"\n",
    "state = torch.load(ckpt, map_location=DEVICE)\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "print(\"✅ Weights loaded from:\", ckpt)\n",
    "\n",
    "# --- tiny, fast forward on a small slice (no heavy work) ---\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "# use the same graph `g_train` you already ToUndirected()'d and moved to DEVICE\n",
    "et = (\"user\",\"interacted\",\"item\")\n",
    "\n",
    "# a single small, consistent mini-subgraph (no negatives; just to test forward)\n",
    "loader = LinkNeighborLoader(\n",
    "    g_train,\n",
    "    num_neighbors={k: [5, 5] for k in g_train.edge_types},  # small, 2 hops\n",
    "    batch_size=512,\n",
    "    edge_label_index=(et, g_train[et].edge_index[:, :2048]),  # small seed set\n",
    "    neg_sampling_ratio=0.0,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "batch = next(iter(loader))\n",
    "batch = batch.to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    h = model(batch.x_dict, batch.edge_index_dict)\n",
    "\n",
    "print(\"Embeddings shapes:\", {k: tuple(v.shape) for k, v in h.items()})\n",
    "print(\"✅ Quick sanity passed.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
